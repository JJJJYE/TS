---
title: "Dynamic Linear Model and Bayesian Structural Time Series"
format: 
  html:
    theme: cosmo
    smooth-scroll: true
    toc: true
    toc-location: right
    # self-contained: true
# author: 
#     - name: J.I. Seo
#       affiliations:
#       - Gyeongguk National University
#     - name: J.W. Lee
#       # affiliations:
#       # - University of Missouri
      
number-sections: true
highlight-style: pygments
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(width=200)
```

## Amtrak

예제 데이터로 사용하는 `"Amtrak.csv"`은 1991년 1월부터 2004년 3월까지 미국 철도 회사인 암트랙에서 제공한 월간 승객 수(단위 : 1,000명)가 기록되어져 있다. 


### 데이터 불러오기

```{r, eval = F}
pacman::p_load("dlm", "bsts",
               "forecast",
               "dplyr")

Amtrak.data <- read.csv(".../Amtrak.csv")          # 데이터 불러오기

Amtrak.data %>%
  as_tibble
```

```{r, echo = F}
pacman::p_load("dlm", "bsts",
               "forecast",
               "dplyr")

Amtrak.data <- read.csv("./DATA/Amtrak.csv")             # 데이터 불러오기

Amtrak.data %>%
  as_tibble
```


### 데이터 전처리

```{r}
# 1. Create Predictor Variable
ridership.df <- Amtrak.data %>%
  dplyr::mutate(Lag1 = dplyr::lag(Ridership, 
                                  n = 1)) %>%      # 바로 이전 과거에 관측된 값을 예측 변수로 생성
  na.omit()                                        # 결측치 NA가 포함된 행 제거 -> 첫 번째 시계열은 과거 관측값이 없기 때문에 변수 Lag1에 NA 생성 
  
ridership.df %>%
    as_tibble

# 2. Convert to ts for Target
ridership.ts <- ts(ridership.df$Ridership, 
                   start = c(1991, 2),            # 시계열의 시작 연도 / c(1991, 2) : 1991년 2월 -> 첫 번째 시계열은 제거했기 때문
                   frequency = 12)                # 주기 / 월별 시계열로 1년에 12번 관측


# 시계열 그림
plot(ridership.ts, 
     xlab = "Time", ylab = "Ridership (in 000s)",
     ylim = c(1300, 2300))
```

`Caution!` CSV 파일로 불러온 데이터를 살펴보면 승객 수를 포함하는 변수 `Ridership`가 수치형임을 알 수 있다. 시계열 데이터 분석을 위해 함수 `ts()`를 이용하여 해당 변수를 시계열 객체로 변환해야 한다.  
`Result!` 시계열 그림을 살펴보면 `Amtrak` 데이터는 U자 형태의 추세를 발견할 수 있으며, 여름(7월과 8월) 동안에 승객이 급증하는 뚜렷한 계절변동도 볼 수 있다.


### 데이터 분할

`Caution!` 시계열 데이터 분석 시 모형의 과적합을 피하고 미래 데이터에 대한 예측력을 계산하기 위해 `Training Dataset`과 `Test Dataset`으로 분할해야 한다. 시계열 데이터의 경우, 시간에 의존하기 때문에 시간 순서를 고려하여 데이터를 분할해야 한다. 즉, 앞 시점의 데이터를 `Training Dataset`로 사용하여 모형을 구축하고, 뒷 시점의 데이터를 `Test Dataset`로 사용하여 구축된 모형의 성능을 평가한다. 여기서는 데이터 분할을 위해 함수 `window()`를 사용한다.

```{r}
# Partition for Target
train.ts <- window(ridership.ts, 
                   start = c(1991, 2),            # 분할하고자 하는 시계열의 시작 연도 / c(1991, 2) : 1991년 2월 -> 첫 번째 시계열은 제거했기 때문
                   end = c(2001, 3))              # 분할하고자 하는 시계열의 마지막 연도 / c(2001, 3) : 2001년 3월

test.ts <- window(ridership.ts,
                   start = c(2001, 4))            # 분할하고자 하는 시계열의 시작 연도 / c(2001, 4) : 2001년 4월

nTrain   <- length(train.ts)                      # Training Dataset의 데이터 포인트 개수

nTest   <- length(test.ts)                        # Test Dataset의 데이터 포인트 개수

train.ts %>%
  as_tibble

test.ts %>%
  as_tibble

nTrain
nTest
```


## Dynamic Linear Model

- 상태공간모형(State Space Model)은 관측 가능한 시계열 $Y_t$을 관측할 수 없는/측정되지 않는 상태 $\theta_t$로 표현하여 나타내는 모형이다.
    - 상태는 시간에 따라 변화하는 확률과정으로 볼 수 있다.
- 상태공간모형은 비정상 시계열이나 불규칙적인 패턴이 존재할 경우 유용하다.    
- 상태공간모형 중에서 선형성(linearity)과 정규분포(Gaussian distribution)을 가정한 모형을 `Dynamic Linear Model (DLM)`이라고 한다. 
$$
\begin{align*}
Y_{t}&=F_{t}\theta_{t}+v_{t},~~~~~~~v_{t}\sim N(0,V_{t}), \\
\theta_{t}&=G_{t}\theta_{t-1}+\omega_{t},~~~\omega_{t}\sim N(0,W_{t}).
\end{align*}
$$
    - 첫 번째는 관측방정식, 두 번째는 상태방정식이다.
        - $Y_{t}$ : 시점 $t$에서 시계열
        - $\theta_{t}$ : 시점 $t$에서 상태 
            - 예를 들어, 추세와 계절성 등
        - $F_{t}$, $G_{t}$ : 알고 있는 행렬
        - $v_{t}$, $\omega_{t}$ : 오차
- 시계열에 DLM을 구축하기 위해 package `"dlm"`을 이용할 수 있으며, 전반적인 분석 절차는 다음과 같다.

<center>
![](./image/BSTS_flow.png){width=80%}
</center>
</br>


### 모형 정의

- 시계열에 추세가 존재할 경우, DLM의 대표적인 모형은 `"Local Level Model"`과 `"Local Linear Trend Model"`이다.
    - `"Local Level Model"` : 추세의 수준($\mu_t$) + Noise
        - 함수 `dlmModPoly(1)`을 이용
$$
\begin{align*}
Y_{t}&=\mu_t +v_t,~~~~~~~v_{t}\sim N(0,\sigma^2_v), \\
\mu_{t}&=\mu_{t-1}+ \omega_{t},~~~\omega_{t}\sim N(0,\sigma^2_{\mu}).
\end{align*}
$$   
    - `"Local Linear Trend Model"` : 추세의 수준($\mu_t$) + 추세의 기울기($\delta_t$) + Noise
        - 함수 `dlmModPoly(2)`을 이용
$$
\begin{align*}
Y_{t}&=\mu_t +v_t,~~~~~~~~~~~~~~~~~~~~~~~~v_{t}\sim N(0,\sigma^2_v), \\
\mu_{t}&=\mu_{t-1}+ \delta_{t-1}+\omega_{1,t},~~~\omega_{1,t}\sim N(0,\sigma^2_{\mu}),\\
\delta_{t}&=\delta_{t-1} + \omega_{2,t},~~~~~~~~~~~~~~~~\omega_{2,t}\sim N(0,\sigma^2_{\delta}).
\end{align*}
$$   
- 시계열에 계절성(계절 주기 : $s$)이 존재할 경우, DLM의 대표적인 모형은 `"Seasonal Factor Model"`이다.
    - 함수 `dlmModSeas(s)`을 이용
- 시계열에 추세와 계절성이 존재한다면, `Level + Slope + Season + Noise` 형태의 DLM을 고려할 수 있다.
    - 함수 `dlmModPoly(2) + dlmModSeas(s)`을 이용
- $j$개의 예측 변수(Predictor Variable)에 대한 회귀모수도 DLM에 포함할 수 있다.
    - 절편과 예측 변수에 대한 회귀모수 $\beta$가 시간의 흐름에 따라 일정하다면, 함수 `dlmModReg(..., dW = rep(0, j+1))`
    - 절편과 예측 변수에 대한 회귀모수 $\beta$가 시간의 흐름에 따라 변한다면, 함수 `dlmModReg(..., dw = c(각 회귀모수의 분산))`
        - $\beta_{i, t}=\beta_{i, t-1} + \omega_{{\beta_i}, t},\;\; \omega_{{\beta_i}, t}\sim N(0, \sigma^2_{\beta_i}), \;\; i = 0, \ldots, j$

</br>

```{r, eval = F}
# Local Level Model
Local.level <- function(p){
  
  mod          <- dlmModPoly(1)        # Local Level Model
  
  V(mod)       <- exp(p[1])            # 관측방정식의 오차의 분산
  diag(W(mod)) <- exp(p[2])            # 상태방정식의 오차의 분산(\sigma^2_{\mu})

  return(mod)  
}
```

```{r, eval = F}
# Local Linear Trend Model
Local.linear.trend <- function(p){
  
  mod               <- dlmModPoly(2)   # Local Linear Trend Model
  
  V(mod)            <- exp(p[1])       # 관측방정식의 오차의 분산
  diag(W(mod))[1:2] <- exp(p[2:3])     # 상태방정식의 오차의 분산(\sigma^2_{\mu}, \sigma^2_{\delta})

  return(mod)  
}
```

```{r, eval = F}
# Seasonal Factor Model
Season.factor <- function(p){
  
  mod           <- dlmModSeas(12)      # Seasonal Factor Model / 계절 주기 = 12
  
  V(mod)        <- exp(p[1])           # 관측방정식의 오차의 분산
  diag(W(mod))[ <- exp(p[2])           # 상태방정식의 오차의 분산(\sigma^2_{\alpha})

  return(mod)  
}
```


```{r}
# Local Linear Trend + Seasonal Factor Model
Local.trend.season <- function(p){
  
  mod               <- dlmModPoly(2) +     # Local Linear Trend Model
                       dlmModSeas(12)      # Seasonal Factor / 계절 주기 = 12
  
  V(mod)            <- exp(p[1])           # 관측방정식의 오차의 분산
  diag(W(mod))[1:3] <- exp(p[2:4])         # 상태방정식의 오차의 분산(\sigma^2_{\mu}, \sigma^2_{\delta}, \sigma^2_{\alpha})

  return(mod) 
}
```

```{r}
# Local Linear Trend + Seasonal Factor + Regression Model
# 예측 변수가 1개인 경우
Local.trend.season.reg <- function(p, x.mat){
  
  mod               <- dlmModReg(x.mat) +  # 예측 변수에 대한 회귀계수 
                       dlmModPoly(2) +     # Local Linear Trend Model
                       dlmModSeas(12)      # Seasonal Factor / 계절 주기 = 12

  
  V(mod)            <- exp(p[1])           # 관측방정식의 오차의 분산
  diag(W(mod))[1:5] <- exp(p[2:6])         # 회귀모수의 분산(절편의 분산과 1개의 예측 변수에 대한 분산) + 상태방정식의 오차의 분산(\sigma^2_{\mu}, \sigma^2_{\delta}, \sigma^2_{\alpha}) 
  
  return(mod) 
}

```

`Caution!` 예제 데이터 `Amtrak`은 추세와 계절성을 동시에 가지고 있는 시계열로써 `Local Linear Trend + Seasonal Factor Model`을 이용하여 분석을 수행한다.


### 모수 추정

- Package `"dlm"`에서 함수 `dlmMLE()`를 이용하면 최대가능도 추정방법으로 정의된 모형에 대한 모수를 추정할 수 있다.
    - 모수 : 관측방정식과 상태방정식에 포함된 오차의 분산

```{r}
mle1 <- dlmMLE(train.ts, 
               parm = c(0.1, 1.1 ,1,1, 1.1),   # 초기값
               build = Local.trend.season )    # 정의한 모형 in 2-1

# 모수의 수렴 여부
ifelse(mle1$convergence==0, print("converge"), print("did not converge") )
```


```{r}
# 추정된 오차의 분산을 이용하여 모형 구축
modelfit <- Local.trend.season(mle1$par)  

# 추정된 관측방정식의 오차의 분산
V(modelfit) 
```

`Result!` 관측방정식의 추정된 오차의 분산은 $\sigma^2_v = 1447.764$이다.

```{r}
# 추정된 상태방정식의 오차의 분산(\sigma^2_{\mu}, \sigma^2_{\delta}, \sigma^2_{\alpha})
diag(W(modelfit)) 
```

`Result!` 상태방정식의 추정된 오차의 분산은 $\sigma^2_{\mu} = 1.147318e+03$ (추세의 수준), $\sigma^2_{\delta} = 8.623064e-16$ (추세의 기울기), $\sigma^2_{\alpha} = 6.566027$ (계절성)이다.


### 상태 추정

- DLM은 `Kalman Filtering`과 `Kalman Smoothing`방법을 이용하여 관측할 수 없는 상태 $\theta_{t}$를 추정할 수 있다.
  - `Kalman Filtering` : 과거와 현재의 관측값($y_{1},\ldots,y_{t}$)을 이용하여 상태의 현재값($\theta_{t}$)을 추정
  - `Kalman Smoothing` : 주어진 모든 관측값 ($y_{1},\ldots,y_{T}$)을 이용하여 상태의 과거값($\theta_{t}$)을 추정


#### Kalman Filtering

- 함수 `dlmFilter()`를 이용하여 `Kalman Filtering`을 수행할 수 있다.

```{r}
filtering <- dlmFilter(train.ts, 
                       modelfit)

# 구조 확인
str(filtering, 1)             
```

`Result!` 함수 `dlmFilter()`는 9개의 결과를 리스트로 반환한다.

1. `y` : 시계열의 관측값
2. `mod` : [모수 추정][모수 추정]에서 추정된 모형
3. `m` : Filtering 분포 $\pi(\theta_t|y_{1:t})$의 평균
    - 즉, $\theta_t|y_{1:t} \sim N(m_t, C_t)$의 $E(\theta_t|y_{1:t})=m_t$
4. `U.C/D.C` : Filtering 분포 $\pi(\theta_t|y_{1:t})$의 공분산행렬의 특이값 분해
    - 즉, $\theta_t|y_{1:t} \sim N(m_t, C_t)$의 $C_t$의 특이값 분해
5. `a` : 예측 분포 $\pi(\theta_{t+1}|y_{1:t})$의 평균
    - 즉, $\theta_{t+1}|y_{1:t} \sim N(a_{t+1}, R_{t+1})$의 $E(\theta_{t+1}|y_{1:t})=a_{t+1}$
    - $a_{t+1} = E(\theta_{t+1}|y_{1:t})=G_{t+1} m_{t}$
6. `U.R/D.R` : 예측 분포 $\pi(\theta_{t+1}|y_{1:t})$의 공분산행렬의 특이값 분해
    - 즉, $\theta_{t+1}|y_{1:t} \sim N(a_{t+1}, R_{t+1})$의 $R_t$의 특이값 분해
7. `f` : 1시점 앞선 시계열 예측값
    - $f_{t+1} = E(Y_{t+1}|y_{1:t})=F_{t+1}a_{t+1}$
    

```{r}
# 상태(추세의 수준/기울기와 계절성)의 추정값
filtering$m
```

`Result!` `Training Dataset`의 각 시점에 대한 상태의 추정값이다. 예제 데이터 `Amtrak`의 `Training Dataset`은 1991년 1월부터 시작하는데 출력 결과의 첫 번째 시점이 1990년 12월인 이유는 초기값($m_0$)에 대한 0시점부터 보여주기 때문이다.  
1열은 추세의 수준 ($\mu_{t}$), 2열은 추세의 기울기 ($\delta_{t}$), 3열부터 13열은 계절성($\alpha_t$)에 대한 추정 결과를 나타낸다.



```{r}
# 상태(추세의 수준/기울기와 계절성)의 한 시점 예측값
filtering$a
```

`Result!` `Training Dataset`의 각 시점에 대한 상태의 예측값이다. 첫 번째 시점의 추정값이 모두 0인 이유는 $a_1 = G_1 m_0 = 0$이기 때문이다.
1열은 추세의 수준 ($\mu_{t}$), 2열은 추세의 기울기 ($\delta_{t}$), 3열부터 13열은 계절성($\alpha_t$)에 대한 예측 결과를 나타낸다.



```{r}
# Kalman Filtering에 의한 시계열 추정값
filtering$f
```

`Result!` `Training Dataset`의 각 시점에 대한 시계열의 추정 결과이다. 첫 번째 값 $E(Y_{1}|y_{0})$은 계산할 수 없기에 초기값으로 대체되었으며, 일반적으로 해당 값은 버린다.



```{r}
# 관측된 시계열과 추정된 시계열에 대한 그림

## 1. 추정된 시계열에 대한 그림
plot(dropFirst(filtering$f),    # 첫 번째 값 제거
     col = "blue",              # 선 색깔
     lwd = 2,                   # 선 굵기
     lty = 2,                   # 선 종류
     ylab = "Ridership")        # y축 이름

## 2. 관측된 시계열에 대한 그림
lines(train.ts,
      lty = 1, 
      lwd = 2, 
      col = "black") 

## 3. 범례
legend("bottomleft",            # 위치
       legend = c("Data", "Estimation Result"), 
       col = c("black", "blue"),
       lty = 1:2,               
       lwd = 2)
```

`Result!` 앞 시점에서 추정이 잘 안되는 이유는 해당 시점까지 주어진 정보(관측값)가 작아 불확실성이 크기 때문이다.



```{r}
# 추세의 수준에 대한 추정 결과
plot(dropFirst(filtering$m[,1]),     # 첫 번째 값 제거
     ylab = "Level")

# 추세의 기울기에 대한 추정 결과
plot(dropFirst(filtering$m[,2]),     # 첫 번째 값 제거
     ylab = "Slope")
```

`Result!` 추세의 수준과 기울기가 시간에 따라 변화하는 것을 알 수 있다.



```{r}
# 계절성에 대한 추정 결과
plot(dropFirst(filtering$m[,3]),     # 첫 번째 값 제거 
     ylab = "")
```


#### Kalman Smoothing

- 함수 `dlmSmooth()`를 이용하여 `Kalman Smoothing`을 수행할 수 있다.

```{r}
smoothing <- dlmSmooth(train.ts,
                       modelfit)

# 구조 확인
str(smoothing, 1)
```

`Result!` 함수 `dlmSmooth()`는 3개의 결과를 리스트로 반환한다.

1. `s` : Smoothing 분포 $\pi(\theta_t|y_{1:T})$의 평균
2. `U.S/D.S` : Smoothing 분포 $\pi(\theta_t|y_{1:T})$의 공분산행렬의 특이값 분해


```{r}
# 관측된 시계열과 추정된 시계열에 대한 그림

## 1. Kalman Smoothing에 의해 추정된 시계열 값
theta         <- modelfit$GG%*%t(smoothing$s)  # 상태의 한 시점 예측값 : theta_{t} = G_{t}s_{t-1}
fitted_smooth <- modelfit$FF%*%theta           # 시계열의 추정값 : Y_{t} = F_{t}theta_{t}

## 2. 관측된 시계열에 대한 그림
plot(train.ts, 
     ylab = "Ridership", 
     lwd = 2)                                  # 선 굵기

## 3. 추정된 시계열에 대한 그림
time <- as.vector(time(train.ts))              # 시간
lines(time, fitted_smooth[1:nTrain],           # x축 : 시간, y축 : 추정된 시계열 값
      col = "blue",                            # 선 색깔
      lwd = 2,                                 # 선 굵기
      lty = 2)                                 # 선 종류

## 4. 범례
legend("bottomleft",                           # 위치
       legend = c("Data", "Estimation Result"), 
       col = c("black", "blue"),
       lty = 1:2,               
       lwd = 2)
```

`Result!` `Kalman Filtering`과 다르게 전반적으로 관측값과 추정값이 비슷한 것을 볼 수 있다. `Kalman Smoothing`은 주어진 모든 관측값을 이용하여 상태를 추정하는 반면, `Filtering`은 과거와 현재값만을 이용하여 상태를 추정하기 때문에 일반적으로 `Kalman Smoothing`의 추정 결과가 더 좋다.



```{r}
# 추세의 수준에 대한 추정 결과
plot(smoothing$s[,1],     
     ylab = "Level")

# 추세의 기울기에 대한 추정 결과
plot(smoothing$s[,2],     
     ylab = "Slope")
```

`Result!` 추세의 수준과 기울기가 시간에 따라 변화하는 것을 알 수 있다.


```{r}
# 계절성에 대한 추정 결과
plot(smoothing$s[,3],     
     ylab = "")
```



### 모형 진단

- DLM은 모형 구축 후 모형 진단을 수행해야 한다.
    1. 잔차의 정규성
    2. 잔차의 독립성
    3. 잔차의 평균이 0인지 확인

</br>

`Caution!` 모형 진단을 수행할 때는 함수 `residuals()`를 이용하여 잔차를 계산할 수 있으며, `Kalman Filtering`을 통해 얻어진 결과의 잔차를 이용한다.

```{r}
# 잔차의 정규성
qqnorm(residuals(filtering, sd = FALSE))
qqline(residuals(filtering, sd = FALSE))
```

`Result!` 점들이 직선에 가까우므로 잔차는 정규분포를 따르는 것을 알 수 있다.

```{r}
# 잔차의 독립성
tsdiag(filtering, main = "")
```

`Result!` ACF 그림을 살펴보면 시차가 0일 때를 제외하고 막대의 선이 모두 파란색 점선 안에 있으므로 잔차는 1보다 큰 모든 시차에서 통계적으로 유의한 상관관계가 존재한다는 증거가 부족하다.

```{r}
# 잔차의 평균이 0인지 확인
plot(residuals(filtering, sd = FALSE),
     ylab = " Residual")
abline(h = 0)
```


### 예측

- 예측은 함수 `dlmForecast()`를 이용하여 수행할 수 있다.

</br>

`Caution!` 함수 `dlmForecast()`에는 `Kalman Filtering`을 이용하여 추정된 모형 결과를 입력해야 한다.

```{r}
pred <- dlmForecast(filtering,          # dlmForecast(filtering model)
                    nAhead = nTest)     # Test Dataset의 데이터 포인트 개수만큼 예측값 계산 

# 구조 확인
str(pred, 1)
```

`Result!` 함수 `dlmForecast()`는 4개의 결과를 리스트로 반환한다.

1. `a` : 미래 시점의 상태에 대한 평균
2. `R` : 미래 시점의 상태에 대한 공분산행렬
3. `f` : 미래 시점의 시계열에 대한 평균
4. `Q` : 미래 시점의 시계열에 대한 분산



```{r}
# Test Dataset에 대한 예측 결과
pred$f
```



```{r}
# 예측 결과에 대한 그림

## 1. 관측된 시계열에 대한 그림
plot(train.ts, 
     xlim = c(1991, 2006.25), ylim = c(1300, 2600),
     ylab = "Ridership")

## 2. Kalman Filtering에 의해 추정된 시계열에 대한 그림 
lines(dropFirst(filtering$f),           # filtering$f : In 2-3-1
      lty = 2,                          # 선 종류
      lwd = 2,                          # 선 굵기
      col = "blue")                     # 선 색깔

## 3. Test Dataset에 대한 시계열 그림
lines(test.ts)

## 4. Test Dataset에 대해 예측된 시계열에 대한 그림
lines(pred$f,
      lty = 2,                          # 선 종류
      lwd = 2,                          # 선 굵기
      col = "blue")                     # 선 색깔

## 5. 95% Predictive Interval (PI)
### 5-1. For x축
timelo <- seq(tail(time, 1) + 1/12, by = 1/12, 
              length = nTest)

### 5-2. 95% PI
polygon(x = c(timelo, rev(timelo)),
        y = c(pred$f + qnorm(0.975)*sqrt(unlist(pred$Q)),      # Using Gaussian Dist.
            rev(pred$f - qnorm(0.975)*sqrt(unlist(pred$Q)))),  # Using Gaussian Dist.
        col = scales::alpha("blue", alpha = 0.2))              # 색깔

## 6. 범례
legend("topright",                      # 위치
       legend = c("Data", "Fitted filtering"), 
       col = c("black", "blue"),
       lty = 1:2,               
       lwd = 2)
```


```{r}
# 예측 정확도
forecast::accuracy(pred$f, test.ts)    
```



## Bayesian Structural Time Series

- Bayesian Structural Time Series (BSTS)는 `Structural Time Series Model에 Bayesian 기법을 적용`하는 방법이다.
- Structural Time Series Model은 Linear Gaussian State Space Model로써 `DLM과 동일한 개념`이다. 
$$
\begin{align*}
Y_{t}&=Z^{T}_{t}\theta_{t}+\epsilon_{t},~~~~~~~\epsilon_{t}\sim N(0, \sigma^2_{\epsilon}), \\
\theta_{t+1}&=T_{t}\theta_{t}+R_{t}\eta_{t},~~~\eta_{t}\sim N_{q}(0,Q_{t}).
\end{align*}
$$
    - 첫 번째는 관측방정식, 두 번째는 상태방정식이다.
        - $Y_{t}$ : 시점 $t$에서 시계열
        - $\theta_{t}$ : 시점 $t$에서 상태 
            - 예를 들어, 추세와 계절성 등 
   - $Z_{t}$, $T_{t}$, $R_{t}$ : 0과 1을 포함하여 알고 있는 값과 미지의 모수를 포함하는 행렬
      - $Z_{t}$ : $p\times 1$ 결과 행렬 (Output Matirx)
      - $T_{t}$ : $p\times p$ 전이 행렬 (Transition Matrix)
      - $R_{t}$ : $p\times q$ 제어 행렬 (Control Matrix)
   - $\epsilon_{t}$, $\eta_{t}$ : 오차로써, 연속적으로 상관관계가 없으며 또한 모든 기간 동안 서로 상관관계가 없는 것으로 가정한다.
      - $\eta_{t}$ : $q\times q$ 상태확산행렬(State Diffusion Matrix) $Q_{t}$을 가진 $q \times 1$ 벡터 ($q\le d$)
      
### Package BSTS

- BSTS는 package `"bsts"`를 이용하여 다룰 수 있다.
    - 해당 package는 BSTS 모형의 사후분포로부터 Markov chain Monte Carlo (MCMC) 표본을 추출하여 모형 구축과 예측을 수행한다.
    
</br>    
    
#### Trend Model

##### Local Level Model

- 시계열을 추세의 수준 $\mu_{t}$로만 표현한 가장 간단한 모형식이다.
    - Random Walk + 오차
    - $Z^{T}_{t} = 1$
    - $T_{t}  = 1$
    - $\theta_{t}=\mu_{t}$
    - $R_{t} = 1$
    - $\eta_{t} = \xi_{t}$ 

$$
\begin{align*}
Y_{t} &= \mu_{t} + \epsilon_{t},~~~~\epsilon_{t}\sim N(0, \sigma^2_{\epsilon}),\\
\mu_{t+1} &= \mu_{t} +  \xi_{t}, ~~~\xi_{t}\sim N(0,\sigma^2_{\xi }).
\end{align*}
$$

- 함수 `AddLocalLevel()`을 이용하여 모형식을 나타낼 수 있다.
    - 오차의 분산 $\sigma^2_{\epsilon}$과 $\sigma^2_{\xi }$에 Inverse Gamma Prior을 할당한다.

```{r, eval=FALSE}
ss <- list()
ss <- bsts::AddLocalLevel(ss, y)          # y : Time Series 
```


##### Local Linear Trend Model

- 시계열을 추세의 수준 $\mu_{t}$과 추세의 기울기(=추세의 증가률) $\delta_{t}$로 표현한 모형식이다.
    - $Z^{T}_{t} = (1, 0)$
    - $T_{t}  = \left[\begin{matrix}1 &  1\\ 0 &  1 \end{matrix}\right]$
    - $\theta_{t}=(\mu_{t}, \delta_{t})^{T}$
    - $R_t=\left[\begin{matrix} 1 & 0 \\ 0 & 1 \end{matrix}\right]$
    - $\eta_{t}=(\xi_{t},\zeta_{t})^{T}$
$$
\begin{align*}
Y_{t} &= \mu_{t} + \epsilon_{t},~~~~~~~~~~~\epsilon_{t}\sim N(0, \sigma^2_{\epsilon}),\\
\mu_{t+1} &= \mu_{t} + \delta_{t} + \xi_{t}, ~~~\xi_{t}\sim N(0,\sigma^2_{\xi }),\\
\delta_{t+1} &= \delta_{t} + \zeta_{t}, ~~~~~~~~~~~~\zeta_{t}\sim N(0,\sigma^2_{\zeta}).
\end{align*}
$$
- Local Level Model보다 유연하며, 단기 예측에 유용하다.
- 함수 `AddLocalLinearTrend()`을 이용하여 모형식을 나타낼 수 있다. 
    - 오차의 분산 $\sigma^2_{\epsilon}$, $\sigma^2_{\xi }$와 $\sigma^2_{\zeta}$에 Inverse Gamma Prior을 할당한다.
    
```{r, eval=FALSE}
ss <- list()
ss <- bsts::AddLocalLinearTrend(ss, y)   # y : Time Series 
```


#### Seasonality Model


##### Regression with Seasonal Dummy Variables

- 시계열의 계절 주기가 $s$일 때, $s$개의 더미 변수에 대한 회귀모형으로 모형식을 나타낼 수 있다.
    - $Z^{T}_{t} = (1, 0,\ldots, 0)$
    - $T_{t} = \left[\begin{matrix} -1 & - 1 & \cdots & -1 & -1 \\ 
                                     1 & 0 & \cdots & 0 & 0\\
                                     0 & 1 & \cdots & 0 & 0 \\
                                     \vdots &\vdots &\vdots & \vdots &\vdots \\
                                     0 & 0 & \cdots & 1 & 0 \end{matrix}\right]$
    - $\theta_{t}=(\tau_{t}, \ldots, \tau_{t-s+2})^{T}$
    - $R_{t}=(1,0,\ldots,0)^{T}$
    - $\eta_{t}=\omega_{t}$ 
$$
\begin{align*}
Y_{t} &= \tau_{t} + \epsilon_{t},~~~~~~~~~~\epsilon_{t}\sim N(0, \sigma^2_{\epsilon}),\\
\tau_{t+d} &= -\sum_{i=0}^{s-2} \tau_{t-i\times d} + \omega_{t}, ~~~\omega_{t}\sim N(0,\sigma^2_{\omega}).
\end{align*}
$$
    - $d$ : Season Duration로 주로 1을 지정한다.
- 계절성을 포착하기 위해 흔히 사용되는 모형으로, 서로 다른 주기를 가진 다중 계절성으로 모형을 확장할 수 있다.
- 함수 `AddSeasonal()`을 이용하여 모형식을 나타낼 수 있다.
    - 오차의 분산 $\sigma^2_{\epsilon}$와 $\sigma^2_{\omega}$에 Inverse Gamma Prior을 할당한다.
    
```{r, eval=FALSE}
ss <- list()
ss <- bsts::AddSeasonal(ss, y,           # y : Time Series 
                        nseasons,        # Season의 개수 = Frequency
                        season.duration) # 각 Season에서 관측 개수

# cycle (s) = season.duration * nseasons
```

- 예를 들어, 월별 시계열에 대해 `nseasons = 12`와 `season.duration = 1`를 입력할 수 있다.
- 주별 시계열에 대해 `nseasons = 52`와 `season.duration = 1`를 입력할 수 있다.


#### 모형 훈련*

- 모형 훈련은 함수 `bsts()`을 이용하여 수행할 수 있다.

```{r, eval=FALSE}
bsts(formula, state.specification, family = c("gaussian", "logit", "poisson", "student"), data, niter, seed = NULL, ...)
```

- `formula` : 시계열과 예측 변수의 관계를 표현하기 위한 함수로써 일반적으로 `시계열 ~ 예측 변수`의 형태로 표현한다.
- `state.specification` : 함수`AddLocalLinearTrend()`와 `AddSeasonal()` 등을 포함하고 있는 리스트 
- `family` : 관측방정식의 분포
- `data` : `formula`에 포함하고 있는 변수들의 데이터셋(Data Frame)
- `niter` : 추출하기 원하는 MCMC 표본 개수
- `seed` : 실행할 때마다 동일한 결과가 출력되도록 하는 시드값


### BSTS without 예측 변수

`Caution!` 예제 데이터 `Amtrak`은 추세와 계절성을 동시에 가지고 있는 시계열로써 `Local Linear Trend + Regression with Seasonal Dummy Variables Model`을 이용하여 분석을 수행한다.

$$
\begin{align*}
Y_{t} &= \mu_{t} + \tau_{t}  + \epsilon_{t},~~~~~~~~~~~~~~~~~\epsilon_{t}\sim N(0, \sigma^2_{\epsilon})\\
\mu_{t+1} &= \mu_{t} + \delta_{t} + \xi_{t}, ~~~~~~~~~~~~~~~~~\xi_{t}\sim N(0,\sigma^2_{\xi }),\\
\delta_{t+1} &= \delta_{t} + \zeta_{t}, ~~~~~~~~~~~~~~~~~~~~~~~~~\zeta_{t}\sim N(0,\sigma^2_{\zeta})\\
\tau_{t+d} &= -\sum_{i=0}^{s-2} \tau_{t-i\times d} + \omega_{t}, ~~~~~~\omega_{t}\sim N(0,\sigma^2_{\omega})
\end{align*}
$$


```{r}
# 1. 모형 정의
ss <- list()
ss <- bsts::AddLocalLinearTrend(ss, train.ts)          # Local Linear Trend
ss <- bsts::AddSeasonal(ss, train.ts,                  # Seasonality 
                        nseasons = 12,                 # Due to Monthly Time Series
                        season.duration = 1)          
```

```{r}
# 2. 모형 훈련
set.seed(100)                                          # For 시드 고정
BSTS.fit <- bsts(train.ts, 
                 state.specification = ss, 
                 niter = 1000,                         # niter : MCMC 표본 개수
                 seed = 100)  

summary(BSTS.fit)
```


```{r}
# 3. 예측
burn          <- SuggestBurn(0.1, BSTS.fit)           # 추출된 MCMC 표본에서 버리고자 하는 표본 개수 / 10% 버림

BSTS.forecast <- predict(BSTS.fit,
                         horizon = nTest,             # Test Dataset의 데이터 포인트 개수만큼 예측값 계산 
                         burn = burn, 
                         quantiles = c(0.025, 0.975)) # For 95% Confidence Interval
```


```{r}
# 예측값
BSTS.forecast$mean
```


```{r}
plot(BSTS.forecast)
```


```{r}
# 예측 정확도
forecast::accuracy(BSTS.forecast$mean, test.ts)
```


### BSTS with 예측 변수

`Caution!` 예제 데이터 `Amtrak`은 추세와 계절성을 동시에 가지고 있는 시계열로써 `Local Linear Trend + Regression with Seasonal Dummy Variables Model`을 이용하여 분석을 수행한다. 이때 오차의 분산 $\sigma^2_{\epsilon}$, $\sigma^2_{\xi }$, $\sigma^2_{\zeta}$와 $\sigma^2_{\omega}$에는 Inverse Gamma Prior이 할당되고, 회귀모수 $\beta_i$에는 변수 선택에 유용한 Spike and Slab Prior이 할당된다.

$$
\begin{align*}
Y_{t} &= \mu_{t} + \tau_{t} +\beta_0+\sum_{i=1}^j \beta_j X_{i, t} + \epsilon_{t},~~~~~~~~~~~~~~~~~\epsilon_{t}\sim N(0, \sigma^2_{\epsilon})\\
\mu_{t+1} &= \mu_{t} + \delta_{t} + \xi_{t}, ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\xi_{t}\sim N(0,\sigma^2_{\xi }),\\
\delta_{t+1} &= \delta_{t} + \zeta_{t}, ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\zeta_{t}\sim N(0,\sigma^2_{\zeta})\\
\tau_{t+d} &= -\sum_{i=0}^{s-2} \tau_{t-i\times d} + \omega_{t}, ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\omega_{t}\sim N(0,\sigma^2_{\omega})
\end{align*}
$$


```{r}
# 1. 모형 정의
ss <- list()
ss <- bsts::AddLocalLinearTrend(ss, train.ts)          # Local Linear Trend
ss <- bsts::AddSeasonal(ss, train.ts,                  # Seasonality 
                        nseasons = 12,                 # Due to Monthly Time Series
                        season.duration = 1)          
```

```{r}
# 2. 모형 훈련
## 2-1. Create Data Frame with Time Series and Predictor Variable 
Train.Data <- data.frame("y"= train.ts, 
                         "Lag" = ridership.df$Lag1[1:nTrain])    # In 1-2

Train.Data %>%
  as_tibble

Test.Data  <- data.frame("y"= test.ts,  
                         "Lag" = ridership.df$Lag1[-(1:nTrain)]) # In 1-2
```


```{r}
## 2-2. Train Model
set.seed(100)                                                    # For 시드 고정
BSTS.fit <- bsts(y ~ Lag, 
                 state.specification = ss, 
                 niter = 1000,                                   # niter : MCMC 표본 개수
                 data = Train.Data,
                 seed = 100)  
```


```{r}
# 3. 예측
burn          <- SuggestBurn(0.1, BSTS.fit)           # 추출된 MCMC 표본에서 버리고자 하는 표본 개수 / 10% 버림

BSTS.forecast <- predict(BSTS.fit,
                         horizon = nTest,             # Test Dataset의 데이터 포인트 개수만큼 예측값 계산 
                         newdata = Test.Data[,"Lag"], # Test Dataset에 대한 예측 변수
                         burn = burn, 
                         quantiles = c(0.025, 0.975)) # For 95% Confidence Interval
```


```{r}
# 예측값
BSTS.forecast$mean
```


```{r}
plot(BSTS.forecast)
```


```{r}
# 예측 정확도
forecast::accuracy(BSTS.forecast$mean, test.ts)
```

